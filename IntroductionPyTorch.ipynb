{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "A tensor is a fundamental data structure for neural network. A tensor is generalization of matrix. A 1-dimensional tensor is vector, a two-dimensional tensor is matrix and n-dimensional array is tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "        Arguements\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7) #set the random seed so thigns are predictable\n",
    "\n",
    "features = torch.randn(1, 5) #random nomral variables with five elements\n",
    "\n",
    "weights = torch.randn_like(features) #true weights for our data. Same shape as features\n",
    "\n",
    "bias = torch.randn(1,1) #A single value for bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n",
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the output for this neural network with input features features, weights, and bias. We will use matrix multiplication\n",
    "# between features and weights and add bias element to it. The output is then passed on to activiation fucntion to generate the final result\n",
    "\n",
    "y = activation(torch.sum(features * weights)+bias) #here we do elements by element multiplicatio and bias\n",
    "print(y)\n",
    "\n",
    "# alternatively we could use sum function on tensor\n",
    "y = activation((features*weights).sum() +bias)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matrix multiplication using torch.mm() for high performance\n",
    "# We are goign to resize the weights based on teh shape of features. For matrix multiplifcation we want 1 x 5 * 5 x 1. \n",
    "# we use view on tensor and specify desired shape to get a new tensor with same data element. The view takes (row, column)\n",
    "# this is simply saying activation(torch.mm(features, weigths.view(5,1))+bias). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "y = activation(torch.mm(features, weights.view(features.size()[1], features.size()[0])) +bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Network\n",
    "We have features and weights.The multiplicaiot of weigth and features makes a hidden units. \n",
    "\n",
    "             O           #One output unit \n",
    "\n",
    "         h1      h2      #Two hidden units\n",
    "         \n",
    "    x1       x2      x3  #Three inpu features\n",
    " \n",
    "Our problem is expressed as below:\n",
    "y = xi*wi + b\n",
    "\n",
    "                                                                 [w11 w12]\n",
    "                                                                 [w11 w12]\n",
    "     The hidden lay h is calcualed as h=[h1,h2] = [x1,x2,x3..xn].[:    : ]\n",
    "                                                                 [:    : ]\n",
    "                                                                 [wn1 wn2]\n",
    "                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "tensor([[0.5349, 0.1988, 0.6592]])\n",
      "Weights of features:\n",
      "tensor([[0.6569, 0.2328],\n",
      "        [0.4251, 0.2071],\n",
      "        [0.6297, 0.3653]])\n",
      "Weights of hidden units:\n",
      "tensor([[ 0.3775],\n",
      "        [-0.9509]])\n",
      "Hidden Units:\n",
      "tensor([[0.2959, 0.2123]])\n",
      "Output    tensor([[0.1409]])\n",
      "tensor([[0.1409]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Generate some data\n",
    "#set the random seed so we are getting the same set of data each time\n",
    "torch.manual_seed(7)\n",
    "\n",
    "#Features are three random normal variables\n",
    "features = torch.rand((1,3))\n",
    "\n",
    "#Define the size of each layer in the network\n",
    "n_input = features.shape[1] #Number of input units, this must match the number of input features. our input features is 1 x 3 matrix and thus we have 3 features in this case\n",
    "n_hidden = 2 #Number of hidden units\n",
    "n_output = 1 #Number of outputs\n",
    "\n",
    "\n",
    "#weigths for input to hidden layer\n",
    "w1 = torch.rand(n_input, n_hidden)\n",
    "\n",
    "#Weights for hidden layer to output layer\n",
    "w2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "#Bias\n",
    "B1 = torch.randn((1,n_hidden))\n",
    "B1 = torch.randn((1,n_output))\n",
    "\n",
    "\n",
    "#printing input data\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "\n",
    "print(\"Weights of features:\")\n",
    "print(w1)\n",
    "\n",
    "print(\"Weights of hidden units:\")\n",
    "print(w2)\n",
    "\n",
    "h = activation(torch.mm(features, w1)+B1)\n",
    "output = activation(torch.mm(h, w2)+B1)\n",
    "\n",
    "\n",
    "print(\"Hidden Units:\")\n",
    "print(h)\n",
    "print(\"Output:\")\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numpy to Torch and back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07630829 0.77991879 0.43840923]\n",
      " [0.72346518 0.97798951 0.53849587]\n",
      " [0.50112046 0.07205113 0.26843898]\n",
      " [0.4998825  0.67923    0.80373904]]\n",
      "tensor([[0.0763, 0.7799, 0.4384],\n",
      "        [0.7235, 0.9780, 0.5385],\n",
      "        [0.5011, 0.0721, 0.2684],\n",
      "        [0.4999, 0.6792, 0.8037]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               #import numpy\n",
    "np.random.seed(7)\n",
    "a = np.random.rand(4,3)          #a numpy array\n",
    "print(a)\n",
    "b = torch.from_numpy(a)          #creata a tensor from numpy array\\\n",
    "print(b)                         #note than tensor always have dtype which ndarray does not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15261658 1.55983758 0.87681846]\n",
      " [1.44693036 1.95597902 1.07699174]\n",
      " [1.00224093 0.14410227 0.53687796]\n",
      " [0.999765   1.35845999 1.60747807]]\n",
      "tensor([[0.1526, 1.5598, 0.8768],\n",
      "        [1.4469, 1.9560, 1.0770],\n",
      "        [1.0022, 0.1441, 0.5369],\n",
      "        [0.9998, 1.3585, 1.6075]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b.numpy()                        #gives back numpy array. Memory is shared between numpy and torch\n",
    "b.mul_(2)                        #inplace operation of multipying by 2 on tensor, changes the value of numpy array\n",
    "print(a)                        #Notice the changed values\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "#define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5, .5, .5), (.5, .5, .5)),])\n",
    "\n",
    "#Downloa dn load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
